{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "torch.cuda.manual_seed_all\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/u/wangnisn/devel/machine_learning_kinetics/ml_kinetics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlk import learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vortex = {'eqn_type':'vortex',\n",
    "        'fcn':'exp(-1/2*(x-cos(t))**2-1/2*(y-sin(t))**2)',\n",
    "        'domain':{'x':[-2,2],'y':[-2,2],'t':[0,2]},\n",
    "        \n",
    "        'err_vec':[0,0,0,1,-1,0,0]}\n",
    "\n",
    "u_t,u_x,u_y,u,x,y = sympy.symbols('u_t u_x u_y u x y')\n",
    "\n",
    "dictionary = (u_x,u_y,x*u_x,y*u_x,x*u_y,y*u_y,u)\n",
    "vortex['dictionary'] = dictionary\n",
    "pde = vortex\n",
    "domain =pde['domain']\n",
    "fcn = pde['fcn']\n",
    "n_points = 50000\n",
    "x = sympy.symbols([x for x in domain.keys()])\n",
    "u_exact = sympy.lambdify(x,sympy.sympify(fcn),'numpy')\n",
    "inputs = {}\n",
    "for key in domain.keys():\n",
    "    min_d = domain[key][0]\n",
    "    max_d = domain[key][1]\n",
    "    #iputs[key] = ((max_d-min_d)*torch.rand((n_points,1),device=device,dtype=dtype,requires_grad=True)+min_d)\n",
    "    tt = np.random.uniform(min_d,max_d,(n_points,1))\n",
    "    inputs[key] = torch.tensor(tt,device=device,dtype=dtype,requires_grad=True)\n",
    "u_exact = sympy.lambdify(x,sympy.sympify(fcn),'numpy')\n",
    "u = u_exact(*[i.detach().cpu() for i in inputs.values()])\n",
    "pde = {}\n",
    "u = u.type(dtype).to(device)\n",
    "pde['inputs'] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0,  Loss u: 1.381e-01, Loss pde: 9.824e-04, Loss_norm: 7.488e+00, Loss tot: 1.381e-01\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:   50,  Loss u: 1.582e-02, Loss pde: 3.499e-01, Loss_norm: 7.488e+00, Loss tot: 1.582e-02\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  100,  Loss u: 2.466e-03, Loss pde: 9.053e-01, Loss_norm: 7.488e+00, Loss tot: 2.466e-03\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  150,  Loss u: 1.351e-03, Loss pde: 9.366e-01, Loss_norm: 7.488e+00, Loss tot: 1.351e-03\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  200,  Loss u: 9.331e-04, Loss pde: 9.299e-01, Loss_norm: 7.488e+00, Loss tot: 9.331e-04\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  250,  Loss u: 6.144e-04, Loss pde: 9.488e-01, Loss_norm: 7.488e+00, Loss tot: 6.144e-04\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  300,  Loss u: 4.713e-03, Loss pde: 1.030e+00, Loss_norm: 7.488e+00, Loss tot: 4.713e-03\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  350,  Loss u: 3.604e-04, Loss pde: 9.510e-01, Loss_norm: 7.488e+00, Loss tot: 3.604e-04\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  400,  Loss u: 2.635e-04, Loss pde: 9.513e-01, Loss_norm: 7.488e+00, Loss tot: 2.635e-04\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  450,  Loss u: 2.825e-04, Loss pde: 9.688e-01, Loss_norm: 7.488e+00, Loss tot: 2.825e-04\n",
      "  coefs: -5.6304e-01   -2.8970e+00    1.4370e-01   -6.2471e-01   -1.4866e+00    1.3500e+00    4.2288e-01  \n",
      "Epoch:  500,  Loss u: 1.795e-04, Loss pde: 2.578e-03, Loss_norm: 1.927e+00, Loss tot: 2.648e-03\n",
      "  coefs:  1.2074e-01   -1.0065e-01    1.4603e-02    8.5312e-01   -8.2739e-01   -5.0117e-03    5.4788e-03  \n",
      "Epoch:  550,  Loss u: 3.686e-04, Loss pde: 3.827e-04, Loss_norm: 1.722e+00, Loss tot: 7.475e-04\n",
      "  coefs:  3.2387e-01   -2.2147e-01    1.2379e-02    5.7754e-01   -5.7323e-01   -1.3861e-02    0.0000e+00  \n",
      "Epoch:  600,  Loss u: 2.439e-04, Loss pde: 2.772e-04, Loss_norm: 1.753e+00, Loss tot: 5.220e-04\n",
      "  coefs:  3.0341e-01   -1.9956e-01    1.0744e-02    6.1933e-01   -6.1076e-01   -9.4545e-03   -3.1581e-05  \n",
      "Epoch:  650,  Loss u: 3.503e-04, Loss pde: 2.119e-04, Loss_norm: 1.724e+00, Loss tot: 5.657e-04\n",
      "  coefs:  3.3494e-01   -2.0650e-01    1.1031e-02    5.8017e-01   -5.7977e-01   -1.2050e-02    0.0000e+00  \n",
      "Epoch:  700,  Loss u: 1.988e-04, Loss pde: 2.010e-04, Loss_norm: 1.775e+00, Loss tot: 4.035e-04\n",
      "  coefs:  2.8957e-01   -1.8254e-01    5.5698e-03    6.4520e-01   -6.4131e-01   -9.0919e-03   -2.1930e-03  \n",
      "Epoch:  750,  Loss u: 1.672e-04, Loss pde: 1.829e-04, Loss_norm: 1.790e+00, Loss tot: 3.542e-04\n",
      "  coefs:  2.6699e-01   -1.6576e-01    2.2291e-03    6.7258e-01   -6.7147e-01   -8.7011e-03   -2.1745e-03  \n",
      "Epoch:  800,  Loss u: 2.263e-04, Loss pde: 1.562e-04, Loss_norm: 1.789e+00, Loss tot: 3.879e-04\n",
      "  coefs:  3.0689e-01   -1.3922e-01   -6.6550e-04    6.5754e-01   -6.5799e-01   -1.8112e-02   -8.2875e-03  \n",
      "Epoch:  850,  Loss u: 5.895e-04, Loss pde: 1.761e-04, Loss_norm: 1.798e+00, Loss tot: 7.686e-04\n",
      "  coefs:  2.4179e-01   -1.1900e-01    1.2817e-03    7.0403e-01   -7.0073e-01   -2.2880e-02   -8.3158e-03  \n",
      "Epoch:  900,  Loss u: 1.327e-04, Loss pde: 1.468e-04, Loss_norm: 1.832e+00, Loss tot: 2.846e-04\n",
      "  coefs:  2.4164e-01   -1.4706e-01   -3.8252e-03    7.1133e-01   -7.1229e-01   -1.0228e-02   -5.4065e-03  \n",
      "Epoch:  950,  Loss u: 4.516e-04, Loss pde: 1.480e-04, Loss_norm: 1.800e+00, Loss tot: 6.036e-04\n",
      "  coefs:  2.5581e-01   -1.5337e-01   -2.4837e-03    6.8855e-01   -6.8901e-01   -5.9022e-03   -5.3445e-03  \n",
      "Epoch: 1000,  Loss u: 1.078e-04, Loss pde: 1.305e-04, Loss_norm: 1.849e+00, Loss tot: 2.438e-04\n",
      "  coefs:  2.1977e-01   -1.3243e-01   -3.0765e-03    7.4071e-01   -7.3743e-01   -9.3997e-03   -6.4043e-03  \n",
      "Epoch: 1050,  Loss u: 1.561e-04, Loss pde: 1.335e-04, Loss_norm: 1.865e+00, Loss tot: 2.942e-04\n",
      "  coefs:  1.9929e-01   -1.3538e-01   -2.8296e-03    7.6289e-01   -7.5909e-01   -1.6415e-03   -3.9286e-03  \n",
      "Epoch: 1100,  Loss u: 1.058e-04, Loss pde: 1.140e-04, Loss_norm: 1.851e+00, Loss tot: 2.259e-04\n",
      "  coefs:  1.8342e-01   -9.0745e-02    0.0000e+00    7.7671e-01   -7.7138e-01   -1.8054e-02   -1.0664e-02  \n",
      "Epoch: 1150,  Loss u: 8.004e-05, Loss pde: 1.097e-04, Loss_norm: 1.884e+00, Loss tot: 1.960e-04\n",
      "  coefs:  1.7995e-01   -1.0841e-01   -3.3225e-03    7.8873e-01   -7.8890e-01   -8.5471e-03   -6.4766e-03  \n",
      "Epoch: 1200,  Loss u: 1.127e-04, Loss pde: 9.959e-05, Loss_norm: 1.881e+00, Loss tot: 2.191e-04\n",
      "  coefs:  2.2704e-01   -1.1409e-01   -7.3228e-03    7.5852e-01   -7.5797e-01   -7.4334e-03   -8.1733e-03  \n",
      "Epoch: 1250,  Loss u: 7.316e-05, Loss pde: 9.415e-05, Loss_norm: 1.883e+00, Loss tot: 1.744e-04\n",
      "  coefs:  1.7663e-01   -1.0255e-01   -1.8290e-03    7.9497e-01   -7.9218e-01   -7.9487e-03   -6.7053e-03  \n",
      "Epoch: 1300,  Loss u: 9.419e-04, Loss pde: 2.905e-04, Loss_norm: 2.003e+00, Loss tot: 1.215e-03\n",
      "  coefs:  2.0188e-01   -2.1562e-01   -2.0364e-02    7.6080e-01   -7.6419e-01    3.4951e-02    5.4241e-03  \n",
      "Epoch: 1350,  Loss u: 6.701e-05, Loss pde: 8.850e-05, Loss_norm: 1.909e+00, Loss tot: 1.627e-04\n",
      "  coefs:  1.7529e-01   -1.1658e-01   -8.0978e-03    8.0156e-01   -8.0197e-01   -1.3504e-03   -4.1014e-03  \n",
      "Epoch: 1400,  Loss u: 2.408e-04, Loss pde: 1.136e-04, Loss_norm: 1.931e+00, Loss tot: 3.578e-04\n",
      "  coefs:  1.8635e-01   -1.0848e-01   -8.6563e-03    8.0431e-01   -8.1235e-01    9.4039e-04   -9.6862e-03  \n",
      "Epoch: 1450,  Loss u: 7.688e-05, Loss pde: 8.024e-05, Loss_norm: 1.914e+00, Loss tot: 1.646e-04\n",
      "  coefs:  1.8429e-01   -9.1911e-02   -5.2619e-03    8.0805e-01   -8.1042e-01   -7.7958e-03   -6.4044e-03  \n",
      "Epoch: 1500,  Loss u: 6.709e-05, Loss pde: 7.629e-05, Loss_norm: 1.909e+00, Loss tot: 1.510e-04\n",
      "  coefs:  1.4645e-01   -8.8832e-02   -2.0921e-03    8.3055e-01   -8.2998e-01   -5.0416e-03   -5.7936e-03  \n",
      "Epoch: 1550,  Loss u: 3.127e-04, Loss pde: 1.163e-04, Loss_norm: 1.883e+00, Loss tot: 4.298e-04\n",
      "  coefs:  1.0639e-01   -7.8947e-02    1.9392e-03    8.4705e-01   -8.3912e-01   -7.2087e-03   -2.0063e-03  \n",
      "Epoch: 1600,  Loss u: 6.125e-05, Loss pde: 6.779e-05, Loss_norm: 1.913e+00, Loss tot: 1.373e-04\n",
      "  coefs:  1.6333e-01   -9.4801e-02   -5.0833e-03    8.2149e-01   -8.1914e-01   -3.3807e-03   -5.4179e-03  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'n_epochs':10000,\n",
    "          'alpha_pde_start':1,\n",
    "           'alpha_pde_end':0.001,\n",
    "           'alpha_l1':1e-5, \n",
    "          'warmup_nsteps':500,\n",
    "          'linearRegInterval':5,\n",
    "          'linearRegression':True,\n",
    "          'width':50,\n",
    "          'layers':8,\n",
    "          'lr':0.002,\n",
    "          'update_coef_in_dl':False,\n",
    "          'logfile':'alpha_decrease.txt'}\n",
    "\n",
    "model = learning(inputs=inputs, u=u, dictionary=dictionary,**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('alpha_decrease.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log['Epoch'].values, log['p3'].values)\n",
    "plt.plot([0,10000],[1,1])\n",
    "plt.ylim(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log['Epoch'], log['p4'])\n",
    "plt.plot([0,10000],[1,1])\n",
    "plt.ylim(-2,-0.4)\n",
    "plt.plot([0,10000],[-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log['Epoch'].values, log['p3'].values)\n",
    "plt.plot([0,10000],[1,1])\n",
    "plt.ylim(0.96,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log['Epoch'], log['p4'])\n",
    "plt.plot([0,10000],[1,1])\n",
    "plt.ylim(-2,-0.4)\n",
    "plt.plot([0,10000],[-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(log['Epoch'], log['Loss_u'], label='loss_u')\n",
    "plt.semilogy(log['Epoch'], log['Loss_pde'], label='loss_pde')\n",
    "plt.semilogy(log['Epoch'], log['Loss_l1'], label='loss_l1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mesh = dt*np.arange(nsteps)\n",
    "x_mesh = dx*np.arange(nx)\n",
    "y_mesh = dy*np.arange(ny)\n",
    "t_mesh, x_mesh,y_mesh = np.meshgrid(t_mesh, x_mesh, y_mesh,indexing='ij')\n",
    "t_mesh = np.reshape(t_mesh, (-1,1))\n",
    "x_mesh = np.reshape(x_mesh, (-1,1))\n",
    "y_mesh = np.reshape(y_mesh, (-1,1))\n",
    "x_mesh /= x_max\n",
    "y_mesh /= y_max\n",
    "t_mesh /= t_max\n",
    "prediction = model(torch.cat([torch.tensor(x_mesh), torch.tensor(y_mesh), torch.tensor(t_mesh)],dim=1).double().cuda(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
